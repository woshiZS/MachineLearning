## Regression

* 应用场景多见于预测股票，PM2.5值。
* 以精灵宝可梦为例，来预测精灵进化之后的combat power。

属性有如下几个：\
1. 当前战斗力Xcp
2. Xs: 精灵种类
3. Xhp:血量
4. Xw:重量，Xh:高度

输出是进化后的战斗力。
### Step1: Model
例如:

> $$ Y = b + W*X_{cp} $$
就是一个计算进化之后战斗力的函数式。
更进一步的，如果函数式可以写成
> $$ Y = b+\sum W_i*X_i $$
> $$ Xi是杰尼龟的各种属性,Wi是权重，b是bias$$

### Step2 Goodness of Function
**有一点需要注意的是后期的Y其实是一个向量，输出会有多个值。**\
我们可以画出对应进化之后战斗力和进化之前战斗力的对比。

#### Loss Function
简而言之就是function的function
> $$L(f) = L(w,b)\\=\sum_{n=1}^{10}(\overset{\wedge}y-(b+w\cdot x_{cp}^n))^2  $$
相当于说就是对实际进化之后的战斗力与估计的战斗力差值的平法求和。

### Step 3:Best Function
Pick the "Best" Function\
我们可以通过Gradient Descent（梯度下降）来计算最值。只要是可微分的就可以做。\
假设我们现在先假定只有一个权重W，不计算bias。使用Gradient Descent的做法如下：
* 随机选一个点$W^0$
* 计算出该点的导数，将该点往函数值减小的方向进行移动
* 现在问题来到了，我们每一步应该移动多少呢？
> $$-\eta \frac{dL}{dW}|_{w=w_0}$$
就是上面个值，其中$\eta$叫做学习率，最终得到下一步，即
> $$ W^0 - \eta \frac{dL}{dW}|_{w=w_0} \rightarrow W^1$$
**注意这里w是指横坐标哦，就是指W在水平方向上移动的距离（正负表示方向）**
* 重复值上步骤经过多次更新之后可能会达到一个局部最优解(local optimal),但是有时候局部最优解并不一定是全局最优解(global optimal),但是linear model的情况下是不会出现这种情况的。

同理，当我们回归到两个变量w,b的情况，是这个时候我们只需要分别对w，b求偏导，类似与之前的步骤不断调整这两个参数的值，来得到使LOSS函数最小的参数对。\
再回到前面所说的local optimal不一定是global optimal的问题，因为我们之前所使用到的LOSS函数是convex的，即凸包，所以任意选取一个起始点，最终得到的结果都是一样的。

### Result
最终我们得到的线性模型肯定不能不会经过所有的点，是会存在一些误差的。**一般来说测试集的LOSS会比训练集的LOSS要更大**\
当我们发现线性函数不能较好的估计实际的战斗力情况时，我们可以尝试用二次函数进行模拟。以此类推,可能三次函数或者更高阶的函数的模拟效果会更好。**但是也会出现在训练集上表现效果很好，但是测试集比较差，这就是所谓的过拟合现象，如下图。（Overfitting）**\
![overfit](img/overfit.PNG)

### Hidden Factors
当我们采集更多的数据时，会发现输入属性和输出可能不是简单的函数关系（**因为函数有个特点只能一对一的映射**），就精灵宝可梦的来说，不同的物种进化前后的战力对比关系可能差异会比较大，所以我们需要对种类进行分类。
1. 如果是某个种族的精灵我们就考虑某一部分的影响，如果不是，就不考虑这一部分的影响。
2. 有点类似与信号与处理中的函数，信号强度大于一个阈值时输出为1，否则为0.这个就叫作分类器,如下图（似乎得手动分类2333，岂不是分不好就完蛋了）。
![category](img/category.PNG)
3. 似乎分类要从输入的本质去进行一个可解释性的分类...... ，除了比较明显的因素之外，另外好像只能靠猜测了。

但是当函数复杂化的时候，又会出现overfitting的问题。

### Regularization
其实就是在原来的LOSS函数上选取较小的W值，这样会使模拟曲线比较平滑，收到输入变动的影响也更小。注意添加的偏移时是不用考虑的，因为bias和曲线的平滑程度是没有关系的。\
<<<<<<< HEAD
![category](img\vibration.PNG)

### 误差分析

Where does the errors come from?

我们通过数据分析得出的$$f^*$$是目标函式的一个估计。这里就有点像统计学里面，采样一部分难免和最终的期望和方差有偏差。讲真我都不喜欢手敲LaTeX公式了，太麻烦了，还不如手写拍照。

之前学概率论有知道，样本的方差的期望是N-1/N倍的方差，当N足够大时候，就可以尽量缩小期望与实际方差之间的差距。

* 所以误差来源于bias和variance，bias就是指的偏移距离，variance指的离散还是紧凑。
* 结论：使用简单的model,variance是很小的，复杂的model容易受数据影响比较大，所以variance比较大。相反，复杂模型bias比较小，简单模型bias比较大。 
* 如果误差主要来自于variance，这就属于overfitting,如果误差主要来源于bias的话，这种就属于underfitting。
* 如果欠拟合，就增加feature，或者换用一个更为复杂的model，如果过拟合，就需要更多的数据，这是一个很有效控制variance的方法，或者说你数据不足的时候，你可以根据自己对这个问题的理解来generate 数据。
* 关于过拟合的另一个方法就是regularization。相当于在Loss function里加一个微小量进行调整，但是这样也会加大bias
* 综上，我们需要权衡bias和variance.有一种不推荐的方法是确定了模型之后再使用测试集去调整Model，这样会造成过拟合。

**N-fold Cross Validation**

三等分数据，两份训练，一份测试loss,调整三份数据的顺序来得到三组不同的loss结果进行比对。
=======
![category](img/vibration.PNG)
>>>>>>> 2b6d2c8d7614695e2acdd9cd77a84e7510fbb916
